{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = mnist_data.read_data_sets(\"data\", one_hot=True, reshape=False, validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X Train: (60000, 28, 28, 1)\n",
      "Shape of Y Train: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(mnist.train.images)\n",
    "x_test = np.array(mnist.test.images)\n",
    "\n",
    "y_train = np.array(mnist.train.labels) \n",
    "y_test = np.array(mnist.test.labels)\n",
    "\n",
    "print(\"Shape of X Train: \" + str(x_train.shape))\n",
    "print(\"Shape of Y Train: \" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digitreconmodel(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), name = \"conv0\")(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool0')(X)\n",
    "    X = Conv2D(filters=16, kernel_size=(4,4), strides=(1,1), name = \"conv1\")(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = Conv2D(filters=24, kernel_size=(4,4), strides=(1,1), name = \"conv2\")(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(units=200, activation='relu', name='fc0')(X)\n",
    "    X = Dense(units=10, activation='softmax', name='fc1')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='CNNDigitReconModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Model\n",
    "digit_keras = digitreconmodel(x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling the Model\n",
    "digit_keras.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.9464 - acc: 0.6768\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.4912 - acc: 0.8379\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.4205 - acc: 0.8582\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.3867 - acc: 0.8731\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.3642 - acc: 0.8791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba0664c4a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the Model\n",
    "digit_keras.fit(x = x_train, y = y_train, epochs = 5, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 666us/step\n",
      "\n",
      "Loss = 0.56362252686\n",
      "Test Accuracy = 0.8128\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "preds = digit_keras.evaluate(x = x_test, y = y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 26, 26, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 10, 10, 16)        2064      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 2, 2, 24)          6168      \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 2, 2, 24)          96        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 2, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "fc0 (Dense)                  (None, 200)               19400     \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 29,914\n",
      "Trainable params: 29,818\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "digit_keras.summary() #plot_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPBdGyaVMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba09c0b2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = 'images/handwriting.jpg'\n",
    "img = image.load_img(img_path, target_size=(28, 28, 1))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "i = digit_keras.predict(i)\n",
    "print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageprepare(argv):\n",
    "    \"\"\"\n",
    "    This function returns the pixel values.\n",
    "    The imput is a png file location.\n",
    "    \"\"\"\n",
    "    im = Image.open(argv).convert('L')\n",
    "    width = float(im.size[0])\n",
    "    height = float(im.size[1])\n",
    "    newImage = Image.new('L', (28, 28), (255))  # creates white canvas of 28x28 pixels\n",
    "\n",
    "    if width > height:  # check which dimension is bigger\n",
    "        # Width is bigger. Width becomes 20 pixels.\n",
    "        nheight = int(round((20.0 / width * height), 0))  # resize height according to ratio width\n",
    "        if (nheight == 0):  # rare case but minimum is 1 pixel\n",
    "            nheight = 1\n",
    "            # resize and sharpen\n",
    "        img = im.resize((20, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wtop = int(round(((28 - nheight) / 2), 0))  # calculate horizontal position\n",
    "        newImage.paste(img, (4, wtop))  # paste resized image on white canvas\n",
    "    else:\n",
    "        # Height is bigger. Heigth becomes 20 pixels.\n",
    "        nwidth = int(round((20.0 / height * width), 0))  # resize width according to ratio height\n",
    "        if (nwidth == 0):  # rare case but minimum is 1 pixel\n",
    "            nwidth = 1\n",
    "            # resize and sharpen\n",
    "        img = im.resize((nwidth, 20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wleft = int(round(((28 - nwidth) / 2), 0))  # caculate vertical pozition\n",
    "        newImage.paste(img, (wleft, 4))  # paste resized image on white canvas\n",
    "\n",
    "    # newImage.save(\"sample.png\n",
    "\n",
    "    tv = list(newImage.getdata())  # get pixel values\n",
    "\n",
    "    # normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
    "    tva = [(255 - x) * 1.0 / 255.0 for x in tv]\n",
    "    return tva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba09b96550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy\n",
    "from PIL import Image, ImageFilter\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Image Processing to fit the algorithm\n",
    "my_image_logic = [imageprepare('images/handwriting.png')]\n",
    "my_image = np.transpose(my_image_logic)\n",
    "newArr=[[0 for d in range(28)] for y in range(28)]\n",
    "k = 0\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        newArr[i][j]=my_image_logic[0][k]\n",
    "        k=k+1\n",
    "plt.imshow(newArr, interpolation='nearest')\n",
    "plt.show()\n",
    "i = np.array(newArr)\n",
    "i = i.reshape(1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
